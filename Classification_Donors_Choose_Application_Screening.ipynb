{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pylab as pl # linear algebra + plots\nfrom scipy.sparse import hstack, vstack\nfrom sklearn import linear_model, datasets\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f77797caf9043a163fc52d72a444a979aefcc875"
      },
      "cell_type": "markdown",
      "source": "# Reading data and preprocessing it\nIn this kernel we will be dealing with 3 kinds of data: numerical, categorical and text"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "scrolled": false,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntest.teacher_number_of_previously_posted_projects = test.teacher_number_of_previously_posted_projects.map(int)\nresources = pd.read_csv(\"../input/resources.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ac3c532b-7785-4aee-bf7a-60624ba207ae",
        "collapsed": true,
        "_uuid": "4d0bacbb9479b60dfa96a0ade754cef155512988",
        "trusted": false
      },
      "cell_type": "code",
      "source": "numerical_cols = []\ncategorical_cols = []\ntext_cols = []",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a465e35b-5932-481a-ae24-ac2f77af180b",
        "scrolled": false,
        "_uuid": "bb3bd09309cba5f4a6821a1cde128f51ae5c33ca",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train[\"origin\"] = \"train\"\ntest[\"origin\"] = \"test\"\ntrain_test = pd.concat([train, test])\ntrain_test.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ef89dcc0bacc1fddf0a47d26938abeebe79c085f",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "resources.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0f3aaf34-d9ca-4556-bda0-17ab436e54d0",
        "collapsed": true,
        "_uuid": "3ab487bb34381347fee781f4f5db9cf00360de5b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Many rows have null values in columns 3 & 4. Thus wherever the data is present in all 4 columns of project_text then we will bring it to 2 columns and drop the remaining columns\nproj_flag = ~(train_test.project_essay_3.isnull() & train_test.project_essay_4.isnull())\ntrain_test[proj_flag] = (train_test[proj_flag]\n                 .assign(project_essay_1 = lambda df: df.project_essay_1 + df.project_essay_2)\n                 .assign(project_essay_2 = lambda df: df.project_essay_3 + df.project_essay_4))\ntrain_test = train_test.drop(['project_essay_3', 'project_essay_4'], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ac7cf6a84788b821c05c6b01c07ee8eec8ea7f7f"
      },
      "cell_type": "markdown",
      "source": "## Null value treatment"
    },
    {
      "metadata": {
        "_uuid": "2de7a76a70e6d7a58c8b8805438adf8b61073dc5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_test.isnull().sum()[train_test.isnull().sum() > 0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1d2c921c7a8d850a010168f520dc32181aca672e"
      },
      "cell_type": "markdown",
      "source": "We find that there are null values in teacher_prefix. The other column is ignored as that is the target variable. "
    },
    {
      "metadata": {
        "_cell_guid": "f4c29633-05ab-4490-bbaf-cbb7ce3f76f7",
        "_uuid": "57fd760f3b5121c18d541207775e688d3038e7b6",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#As teacher_prefix is a categorical variable, we will use mode of that variable to replace the missing values\nmax_count = train_test.teacher_prefix.value_counts().idxmax()\ntrain_test.teacher_prefix = train_test.teacher_prefix.fillna(max_count)\ntrain_test.isnull().sum()[train_test.isnull().sum() > 0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "923aa6c37ac87bfcb2f3e4137ec9ffa35a9866af",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "resources.isnull().sum()[resources.isnull().sum() > 0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "54b45d2d-22f8-4aa2-ad44-008e570f6d54",
        "collapsed": true,
        "_uuid": "737bb30e473a0152425575a41c7f3741ceeb150b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#As description is a text variable, we will simply replace the missing values with X\nresources[\"description\"] = resources[\"description\"].fillna('X')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "64e779ba832a641a106ff1ffbe5706e11630fca9"
      },
      "cell_type": "markdown",
      "source": "## Feature engineering - 1. Resources dataset (Numerical features)\nThe 2nd cell below this where we create features based on descriptive stats(min, max, mean) was inspired from other kernels and was found to have a good impact on the accuracy "
    },
    {
      "metadata": {
        "_uuid": "6b1187d635b584103ec7ae59dcd20aef82916ab4",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "resources[\"desc_len\"] = resources.description.str.len()\nresources[\"total_price\"] = resources.quantity * resources.price\nresources.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7129e3c1-53f0-438e-8371-a4d58d079c8a",
        "collapsed": true,
        "_uuid": "211c01420286c7eb9b9d0bc95bf9d46a94d80665",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def concatenate(series):\n    return ' '.join(map(str, series))\n\nresources_info = resources.groupby('id').agg({'description': [pd.Series.nunique, concatenate],\n                             'quantity': [np.sum],\n                             'price': [np.sum, np.mean], \n                             'desc_len': [np.mean, np.min, np.max], \n                             'total_price': [np.mean, np.min, np.max]})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "54f5e6757a649574f0a5835d4a60b0153c31fc2b",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "resources_info.head(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "62ef32125de138b9219018d247d2fdef73f4688d"
      },
      "cell_type": "markdown",
      "source": "Looks like resources_info is a nested dataframe. We will flatten the dataframe"
    },
    {
      "metadata": {
        "_uuid": "62d87c320c3d848e9982c1d51bb04f5abcff194b",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "resources_info.columns.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "32bc0a52-74e7-46f4-a631-d43c5565dd42",
        "scrolled": true,
        "_uuid": "9f544290341fd9e39617148d8a112d29396de70e",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "resources_info.columns = ['_'.join([col, func]) for col, func in resources_info.columns.values]\nresources_info = resources_info.reset_index()\nresources_info.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c0b83aa9-0f7e-4ee0-bd11-bb6693127b1b",
        "scrolled": false,
        "_uuid": "e5351fc3ce85b02aea7101ca2954fdb73b47ae66",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Adding column names to their respective variable lists\nnumerical_cols += list(resources_info.columns)\nnumerical_cols.remove('id')\nnumerical_cols.remove('description_concatenate')\ntext_cols+=['description_concatenate']\nnumerical_cols",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cd29cb9edcc905d99f975bbdd908ba3251057751"
      },
      "cell_type": "markdown",
      "source": "We will join train_test with resources_info on project_id"
    },
    {
      "metadata": {
        "_cell_guid": "85041f9e-99cf-426e-a8eb-491e39820dcc",
        "scrolled": false,
        "_uuid": "fe1421512f73d576c78cee452e6dac42b90411f7",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_test = train_test.merge(resources_info, how=\"left\", left_on=\"id\", right_on=\"id\")\ntrain_test.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "af1a815d71e5d8aeb8ec8767bafb6e56e38bd349"
      },
      "cell_type": "markdown",
      "source": "## Feature Engineering - 2. Categorical data\nCreating dummy variables for categorical data[](http://)"
    },
    {
      "metadata": {
        "_cell_guid": "fbf7522d-0dc9-4603-8528-10766b84e30c",
        "scrolled": true,
        "_uuid": "5cd2bd26ebf18d7f9272250303a701c3c9a7240f",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_test['submitted_month']= pd.DatetimeIndex(train_test['project_submitted_datetime']).month\ntrain_test['submitted_month'] = train_test['submitted_month'].apply(str)\ndummy_colnames = ['teacher_prefix', 'submitted_month', 'school_state', 'project_grade_category']\ndummies = pd.get_dummies(train_test.loc[:, dummy_colnames])\ntrain_test = pd.concat([train_test, dummies], axis=1)\ntrain_test.head(1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b1301171-baca-45bd-8be0-b21e225792be",
        "collapsed": true,
        "_uuid": "188766b1bb384afcabf86c58366df247f7cda6c1",
        "trusted": false
      },
      "cell_type": "code",
      "source": "categorical_cols += list(dummies.columns)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e34045487c0b6749a3d130d746d8674cda4cd174"
      },
      "cell_type": "markdown",
      "source": "Columns like project_subject_categories and sub_Categories have a lot of combinations of categories separated by commas. We will create one hot encoding for these columns and where ever the value exists the column will have value = 1 "
    },
    {
      "metadata": {
        "_cell_guid": "f38bda5d-38f3-4905-947e-57e361b6a931",
        "_uuid": "82b32d3f8637f8a57e22029aef35b661840b9c74",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def return_unique_elements(col_name):\n    unique_elements = []\n    categories = train_test[col_name].unique().tolist()\n    for s in categories:\n        temp_str = [i.strip() for i in s.split(',')] #It splits the string by comma and returns a list. The whitespace from list elements is then removed\n        unique_elements+=temp_str\n    return set(unique_elements)\n\nunique_categories = return_unique_elements('project_subject_categories')\nunique_subcategories = return_unique_elements('project_subject_subcategories')\n\ntotal_categories = list(unique_subcategories.union(unique_categories))\ntotal_categories",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f9d1647a-4f94-4fe2-98b9-595842de0b7d",
        "scrolled": true,
        "_uuid": "49ca5bdabd4922d17ac09c6f17586caa0f3be312",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#train_test_sample.project_subject_categories.str.contains('Health & Sports') | train_test_sample.project_subject_subcategories.str.contains('Health & Sports')\n\nfor category in total_categories:\n    train_test[category] = np.where(train_test.project_subject_categories.str.contains(category) | train_test.project_subject_subcategories.str.contains(category), 1, 0)\ntrain_test.head(1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "abb4539e-c037-4d0f-b9df-f811e2d17b5e",
        "collapsed": true,
        "_uuid": "ab5fb4e76fcf3000657d82405af2cac6beb42a9e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "categorical_cols += total_categories",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9847947d-1308-4f6a-b062-e62d07520779",
        "collapsed": true,
        "_uuid": "beca10e66ba41fd8d670c3941f95267a3e86d2bd",
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%time\n\ntrain_test_sample = train_test.iloc[:1000, :]\n# vectorizer = CountVectorizer(stop_words=None,\n#                                  max_features=1000,\n#                                  binary=True,\n#                                  ngram_range=(1,2))\n# X = vectorizer.fit_transform(train_test['project_essay_1'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f663ac2b-0aa2-4232-8b7c-e13f6fe3bae4",
        "collapsed": true,
        "_uuid": "0f94be594f37c1b99827d9878e9be9af9745d608",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# %%time\n# tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english', max_features=1000)\n# X = tfidf.fit_transform(train_test['project_essay_1'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "06b2ee19-fe04-41f9-8f73-198878275834",
        "collapsed": true,
        "_uuid": "a9fb3d483c8c3ca7bd1121c955813b47ea8b7267",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# #Getting the tockenized data into dataframe\n# df1 = pd.DataFrame(X.toarray(), columns=tfidf.get_feature_names())\n# df1.columns = ['project_essay_1_'+col for col in df1.columns.values]\n# df1.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "dc20ebd3-587a-4049-9bc5-2b10c9b8c26e",
        "_uuid": "b6be0a696cc2f05c57f1d7d9412bd5c1ea9388f0",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "len(numerical_cols) + len(categorical_cols)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3eda7b022e0cbae84b61e51ad7326a3c03677cd3"
      },
      "cell_type": "markdown",
      "source": "## Feature Engineering - 3. Text data\nHere we use TF-IDF Vectorizer method. We create a dictionary of 2000 most commonly occurring words and normalize them by L2 norm. These 2000 words will serve as an individual feature in the dataset. We considered 4 text variables:  project_essay_1, project_essay_2, project_resource_summary, project_title. "
    },
    {
      "metadata": {
        "_cell_guid": "2b11a410-ae7e-42d1-bd34-e6a70231a606",
        "collapsed": true,
        "_uuid": "7630a0a6ccf1fc3b8ddf42aecf706ba7c4f53b41",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def text_features(col_name):\n    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english', max_features=2000)\n    X = tfidf.fit_transform(train_test[col_name])\n    return X, tfidf.get_feature_names()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "42b8a560-1012-436e-8127-06eed3b2db75",
        "_uuid": "bef579cfd78803c82b2d072ad4e1e72b91ed47ab",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "%%time\ntxt_essay_1, essay_1_features = text_features('project_essay_1')\ntxt_essay_2, essay_2_features = text_features('project_essay_2')\ntxt_summary, summary_features = text_features('project_resource_summary')\ntxt_title, title_features = text_features('project_title')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d4746002a1dc67a7baa1ad5d98c0e8045f1284e5"
      },
      "cell_type": "markdown",
      "source": "As these text features will have a lot of 0's they are stored in a sparse matrix. We then stack them horizontally to create a sparse matrix with 8000 features."
    },
    {
      "metadata": {
        "_cell_guid": "b569c712-4e53-4838-8e21-514ab28fd37e",
        "collapsed": true,
        "_uuid": "3565db0dcb79b96cc9943a485ee1321bb746afb7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# categorical_data_array = train_test[categorical_cols].values\n# txt_essay_1.shape\nX = hstack((train_test[numerical_cols].values, train_test[categorical_cols].values, txt_essay_1, txt_essay_2, txt_summary, txt_title)).tocsr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "669acb6b3051bc6b5898e65c726843aa4d18c875",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "X",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f260f317-c55e-4ccc-ba74-75c1f2351d34",
        "collapsed": true,
        "_uuid": "0426c53b774774170eb36c9ea00b5395450ba807",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#X_train = X[train_test[\"origin\"] == 'train', :] This didn't work as my kernel died due to RAM overflow\nX_train = X[pl.find(train_test[\"origin\"] == 'train'), :]\nX_test = X[pl.find(train_test[\"origin\"] == 'test'), :]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a6bed9a4-c436-4be4-ada2-261f8d1fe5b4",
        "_uuid": "f1e4cd98a2b53517c43f0d40ad5fd45d5a9199db"
      },
      "cell_type": "markdown",
      "source": "Now that train and test features are created our next task is to have a look at number of approvals and rejections. We will also try to create a balanced dataset that is 50% approvals and 50% rejections. Once the balanced dataset is ready we can proceed to modelling where we will start with logistic regression. "
    },
    {
      "metadata": {
        "_cell_guid": "c530faa6-6510-47b3-83a7-e1b7a6dbba41",
        "collapsed": true,
        "_uuid": "03a30b2f11ee4386ed67a55d236fae0052970ea0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Indices of train dataset to create a balanced dataset\nrejection_index = np.array(train[train.project_is_approved == 0].index)\napproval_index = np.array(train[train.project_is_approved == 1].index)\napproval_permuted_index = np.random.permutation(approval_index)[:rejection_index.shape[0]]\n\n#Once we have equal 0's and 1's we will join the indices of the 2 values and then randomly permute them\nbalanced_indices = np.concatenate((approval_permuted_index, rejection_index))\nbalanced_permuted_indices = np.random.permutation(balanced_indices)\n\n#We create X and Y arrays holding the training and testing data respectively\nX_balanced_data = X_train[balanced_permuted_indices, :]\nY_balanced = train.project_is_approved[balanced_permuted_indices].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b8d0a3f3-20fe-4adc-a24f-cf3a0f454465",
        "_uuid": "b04e22b34e06df30714df1f8db6c72807b6b2b66"
      },
      "cell_type": "markdown",
      "source": "## Modeling and Validating data\nFitting a logistic regression model on balanced dataset"
    },
    {
      "metadata": {
        "_cell_guid": "79e59ee4-541a-483e-9391-9fded835b837",
        "collapsed": true,
        "_uuid": "b4465578a84915993aa59523f2c7826c0a6b77d6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# %%time\n# logistic = linear_model.LogisticRegression()\n# model = logistic.fit(X_balanced_data, Y_balanced)\n# print(model.score(X_balanced_data, Y_balanced))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "205132de-10aa-48ad-be8e-49c0dd3fcbe4",
        "_uuid": "c372f140ffc544d8b9c4155f21c0a80466de2486",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "%%time \nlogistic = linear_model.LogisticRegression(penalty=\"l2\", C=0.18285)\nmodel = logistic.fit(X_balanced_data, Y_balanced)\nprint(model.score(X_balanced_data, Y_balanced))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ffd77894-6abe-4e1b-b607-71f261d42b24",
        "scrolled": false,
        "_uuid": "613359b0190089d68646502b9385f4007b6f1952",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "Y_predicted = model.predict_proba(X_balanced_data)[:, 1]\nroc_auc_score(Y_balanced, Y_predicted)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "60597a2f-85c0-4048-bbb7-acdb4825ba11",
        "_uuid": "4ee75c63326c3e9aba22f806dfe2a77bbf13a6d0",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fca19953-e0cd-4283-93ab-306b2a95ef43",
        "collapsed": true,
        "_uuid": "53a0203d0889779db1232e69601ffecfbfdee03a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%time\nY = train.project_is_approved.values\nlogistic = linear_model.LogisticRegression(penalty=\"l2\", C=0.18285)\nmodel = logistic.fit(X_train, Y)\nY_predicted = model.predict_proba(X_train)[:, 1]\nprint(roc_auc_score(Y, Y_predicted))\nprint(model.score(X_train, Y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "_cell_guid": "902543f0-4f3b-4925-8e15-58dfbf616b96",
        "collapsed": true,
        "_uuid": "3b7dd8e8d9a466506e4b334f56a4c16337bf7727",
        "trusted": false
      },
      "cell_type": "code",
      "source": "Y_pred_test = model.predict_proba(X_test)[:, 1]\ntest_output = pd.DataFrame({'id':test.id.values, 'project_is_approved':Y_pred_test})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b8c59fcc-a2e6-4127-88e1-4a309645848f",
        "collapsed": true,
        "_uuid": "ff866d14f7734711c13d5176d14aed18cc784741",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#test_output.to_csv('csv_to_submit.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9b1be895-c1be-49f6-a51e-d087ab7b5dec",
        "collapsed": true,
        "_uuid": "2180f0642f3100543dab20d2bc3f02b725d741ed",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# %%time\n# from sklearn.model_selection import GridSearchCV\n# # Dictionary with parameters names to try during search\n# # We tried a lot of parameters, you may uncomment the code an experiment\n# param_grid = {\"C\": np.linspace(0.24285-0.1, 0.24285+0.1, num=6)\n#              # \"union__numerical_pipe__logtransform__alpha\": [0.8, 1],\n#              # \"union__text_pipe__tf_idf__stop_words\": [None, 'english']\n#              }\n# logistic = linear_model.LogisticRegression()\n\n# # run randomized search\n# grid_search = GridSearchCV(logistic, param_grid=param_grid,\n#                                     scoring='roc_auc',\n#                                     n_jobs=1,\n#                                     verbose=1,\n#                                     cv=3)\n# best_model = grid_search.fit(X_balanced_data, Y_balanced)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "66c84fc5-1973-4fd5-a5ed-56f0df171bbe",
        "collapsed": true,
        "_uuid": "5acd66c08eb98048072b6f6451e98ae329bef46c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# best_model.best_estimator_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "91f4eec4-8b06-42f4-ac35-5ba14a3b9252",
        "_uuid": "61e393708c8f5d1f0dd8aee87b8f5d19232aed2f"
      },
      "cell_type": "markdown",
      "source": "Random Forest "
    },
    {
      "metadata": {
        "_cell_guid": "d545eefc-367e-4933-a617-d63d180d8a43",
        "collapsed": true,
        "_uuid": "0ac5f29f3b1440fd43123911e6b3fb5ad8ea12a6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# %%time\n# from sklearn.ensemble import RandomForestClassifier\n# rf_model = RandomForestClassifier(n_estimators=250, min_samples_split=10, max_features=\"auto\", random_state=0)\n# rf_model = rf_model.fit(X_balanced_data, Y_balanced)\n# Y_predicted = rf_model.predict_proba(X_balanced_data)[:, 1]\n# roc_auc_score(Y_balanced, Y_predicted)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8967543c-6118-427a-8ebc-5e324751458f",
        "collapsed": true,
        "_uuid": "6e077671fa8a96ccf7c7971c65f4e39d810749b8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# from sklearn.model_selection import cross_val_score\n# # rf_model = RandomForestClassifier(n_estimators=500, max_depth=5, max_features=\"auto\", random_state=0)\n# # rf_model = rf_model.fit(X_balanced_data, Y_balanced)\n# # Y_predicted = rf_model.predict_proba(X_balanced_data)[:, 1]\n# CV = 5\n# Y = train.project_is_approved.values\n# rf_model = RandomForestClassifier(n_estimators=500, max_depth=5, max_features=\"auto\", random_state=0)\n# accuracies = cross_val_score(rf_model, X_train, Y, scoring='roc_auc', cv=CV)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5d59695a-c4dd-4d28-a4a2-5b9ec14a3458",
        "collapsed": true,
        "_uuid": "ab1be5b99b9c0f616a5c8bbcf84a76b4c68b1fd8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# cross_val_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "590e11eb-1c17-4b1d-a4c1-b0d44935342d",
        "_uuid": "a3338017581f98818e495d4cae0f8b434d149007"
      },
      "cell_type": "markdown",
      "source": "We will now be doing GridSearch based on cross validation by varying the hyperparameters to choose the best possible model"
    },
    {
      "metadata": {
        "_cell_guid": "1df53074-8a6d-4e57-bdf6-a86e4733f709",
        "collapsed": true,
        "_uuid": "3efab86145a0ec0775d08530aa0f17dec80fbdba",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# %%time\n# # Create hyperparameters range\n# penalty = ['l1', 'l2']\n# C = np.linspace(0.1, 25, num=15)\n# hyperparameters = dict(C=C, penalty=penalty)\n\n# # Create logistic regression\n# logistic = linear_model.LogisticRegression()\n\n# # Create grid search using 5-fold cross validation\n# clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0, scoring='roc_auc')\n\n# # Fit grid search\n# best_model = clf.fit(X_balanced_data, Y_balanced)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}